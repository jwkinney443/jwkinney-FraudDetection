{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries + Loading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Date of Birth\n",
    "train['dob'] = pd.to_datetime(train['dob'], errors='coerce')\n",
    "test['dob'] = pd.to_datetime(test['dob'], errors='coerce')\n",
    "\n",
    "# Age \n",
    "train['age'] = 2024 - train['dob'].dt.year\n",
    "test['age'] = 2024 - test['dob'].dt.year\n",
    "\n",
    "# Name of Individuals\n",
    "train['name'] = train['first'] + ' ' + train['last']\n",
    "test['name'] = test['first'] + ' ' + test['last']\n",
    "\n",
    "# Time\n",
    "train['hours'] = pd.to_datetime(train['unix_time'], unit='s').dt.hour\n",
    "test['hours'] = pd.to_datetime(test['unix_time'], unit='s').dt.hour\n",
    "\n",
    "\n",
    "# Distance from merch\n",
    "train['distance'] = np.sqrt((train['lat'] - train['merch_lat'])**2 + (train['long'] - train['merch_long'])**2)\n",
    "test['distance'] = np.sqrt((test['lat'] - test['merch_lat'])**2 + (test['long'] - test['merch_long'])**2)\n",
    "\n",
    "\n",
    "# Checking if high amount\n",
    "high_value_threshold = train['amt'].quantile(0.9)\n",
    "train['is_high_value_transaction'] = (train['amt'] > high_value_threshold).astype(int)\n",
    "test['is_high_value_transaction'] = (test['amt'] > high_value_threshold).astype(int)\n",
    "\n",
    "# Checking if low amount - ('test' fraud amount)\n",
    "low_value_threshold = train['amt'].quantile(0.1) \n",
    "train['is_low_value_transaction'] = (train['amt'] < low_value_threshold).astype(int)\n",
    "test['is_low_value_transaction'] = (test['amt'] < low_value_threshold).astype(int)\n",
    "\n",
    "def extract_street_name(street):\n",
    "    # Remove any numeric values and keep only street name\n",
    "    street_name = ' '.join([word for word in street.split() if not word.isdigit()])\n",
    "    return street_name\n",
    "\n",
    "# Street name\n",
    "train['street_name'] = train['street'].apply(extract_street_name)\n",
    "test['street_name'] = test['street'].apply(extract_street_name)\n",
    "\n",
    "# Drop fields that are not needed (will tweak if needed)\n",
    "dropped = ['trans_num', 'trans_date', 'trans_time', 'first', 'last', \n",
    "                'street', 'long', 'lat', 'city_pop', 'merch_lat', 'merch_long']\n",
    "\n",
    "train.drop(columns=dropped, inplace=True)\n",
    "test.drop(columns=dropped, inplace=True)\n",
    "\n",
    "cat_col = ['merchant', 'name', 'category', 'gender', 'city', 'state', 'job', 'street_name'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split + Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5096478\ttest: 0.5098628\tbest: 0.5098628 (0)\ttotal: 161ms\tremaining: 3m 21s\n",
      "100:\tlearn: 0.0254661\ttest: 0.0248901\tbest: 0.0248901 (100)\ttotal: 12.2s\tremaining: 2m 18s\n",
      "200:\tlearn: 0.0164606\ttest: 0.0164707\tbest: 0.0164707 (200)\ttotal: 24.8s\tremaining: 2m 9s\n",
      "300:\tlearn: 0.0145468\ttest: 0.0149492\tbest: 0.0149459 (297)\ttotal: 36.7s\tremaining: 1m 55s\n",
      "400:\tlearn: 0.0131180\ttest: 0.0137444\tbest: 0.0137437 (399)\ttotal: 48.1s\tremaining: 1m 41s\n",
      "500:\tlearn: 0.0121021\ttest: 0.0129167\tbest: 0.0129157 (499)\ttotal: 1m\tremaining: 1m 29s\n",
      "600:\tlearn: 0.0115726\ttest: 0.0126704\tbest: 0.0126704 (599)\ttotal: 1m 10s\tremaining: 1m 16s\n",
      "700:\tlearn: 0.0109612\ttest: 0.0122355\tbest: 0.0122355 (699)\ttotal: 1m 21s\tremaining: 1m 3s\n",
      "800:\tlearn: 0.0104235\ttest: 0.0117415\tbest: 0.0117415 (800)\ttotal: 1m 30s\tremaining: 50.7s\n",
      "900:\tlearn: 0.0101569\ttest: 0.0116741\tbest: 0.0116741 (900)\ttotal: 1m 41s\tremaining: 39.2s\n",
      "1000:\tlearn: 0.0098775\ttest: 0.0115819\tbest: 0.0115819 (998)\ttotal: 1m 52s\tremaining: 27.9s\n",
      "1100:\tlearn: 0.0096232\ttest: 0.0115363\tbest: 0.0115358 (1096)\ttotal: 2m 2s\tremaining: 16.6s\n",
      "1200:\tlearn: 0.0088882\ttest: 0.0109193\tbest: 0.0109189 (1198)\ttotal: 2m 13s\tremaining: 5.44s\n",
      "1249:\tlearn: 0.0086613\ttest: 0.0107847\tbest: 0.0107847 (1249)\ttotal: 2m 18s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.01078468536\n",
      "bestIteration = 1249\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x122271e10>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Split data into features and target\n",
    "X = train.drop(columns=['is_fraud'])\n",
    "y = train['is_fraud']\n",
    "X_test = test\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Train model now \n",
    "model = CatBoostClassifier(iterations=1250, depth=6, learning_rate=0.1, loss_function='Logloss', verbose=100)\n",
    "\n",
    "idxs = [X.columns.get_loc(col) for col in cat_col]\n",
    "\n",
    "model.fit(X_train, y_train, eval_set=(X_val, y_val), use_best_model=True, cat_features=idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score + Report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9852309502794939\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     65592\n",
      "           1       0.99      0.98      0.99      8549\n",
      "\n",
      "    accuracy                           1.00     74141\n",
      "   macro avg       0.99      0.99      0.99     74141\n",
      "weighted avg       1.00      1.00      1.00     74141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(X_val)\n",
    "\n",
    "f1 = f1_score(y_val, y_predict)\n",
    "print(f'F1 Score: {f1}')\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved as submission.csv\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': sample_submission['id'],\n",
    "    'is_fraud': y_test_pred\n",
    "})\n",
    "\n",
    "# Save the submission file\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file saved as submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
