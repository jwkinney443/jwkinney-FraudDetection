{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries + Loading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Date of Birth\n",
    "train['dob'] = pd.to_datetime(train['dob'], errors='coerce')\n",
    "test['dob'] = pd.to_datetime(test['dob'], errors='coerce')\n",
    "\n",
    "# Age \n",
    "train['age'] = 2024 - train['dob'].dt.year\n",
    "test['age'] = 2024 - test['dob'].dt.year\n",
    "\n",
    "# Name of Individuals\n",
    "train['name'] = train['first'] + ' ' + train['last']\n",
    "test['name'] = test['first'] + ' ' + test['last']\n",
    "\n",
    "# Time\n",
    "train['hours'] = pd.to_datetime(train['unix_time'], unit='s').dt.hour\n",
    "test['hours'] = pd.to_datetime(test['unix_time'], unit='s').dt.hour\n",
    "\n",
    "\n",
    "# Distance from merch\n",
    "train['distance'] = np.sqrt((train['lat'] - train['merch_lat'])**2 + (train['long'] - train['merch_long'])**2)\n",
    "test['distance'] = np.sqrt((test['lat'] - test['merch_lat'])**2 + (test['long'] - test['merch_long'])**2)\n",
    "\n",
    "\n",
    "# Checking if high amount\n",
    "high_value_threshold = train['amt'].quantile(0.9)\n",
    "train['is_high_value_transaction'] = (train['amt'] > high_value_threshold).astype(int)\n",
    "test['is_high_value_transaction'] = (test['amt'] > high_value_threshold).astype(int)\n",
    "\n",
    "def extract_street_name(street):\n",
    "    # Remove any numeric values and keep only street name\n",
    "    street_name = ' '.join([word for word in street.split() if not word.isdigit()])\n",
    "    return street_name\n",
    "\n",
    "# Street name\n",
    "train['street_name'] = train['street'].apply(extract_street_name)\n",
    "test['street_name'] = test['street'].apply(extract_street_name)\n",
    "\n",
    "# Drop fields that are not needed (will tweak if needed)\n",
    "dropped = ['trans_num', 'trans_date', 'trans_time', 'first', 'last', \n",
    "                'street', 'long', 'lat', 'city_pop', 'merch_lat', 'merch_long']\n",
    "\n",
    "train.drop(columns=dropped, inplace=True)\n",
    "test.drop(columns=dropped, inplace=True)\n",
    "\n",
    "cat_col = ['merchant', 'name', 'category', 'gender', 'city', 'state', 'job', 'street_name'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split + Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5040894\ttest: 0.5037348\tbest: 0.5037348 (0)\ttotal: 154ms\tremaining: 3m 12s\n",
      "100:\tlearn: 0.0252160\ttest: 0.0246609\tbest: 0.0246609 (100)\ttotal: 10.6s\tremaining: 2m\n",
      "200:\tlearn: 0.0169532\ttest: 0.0168011\tbest: 0.0168011 (200)\ttotal: 20.6s\tremaining: 1m 47s\n",
      "300:\tlearn: 0.0143943\ttest: 0.0146012\tbest: 0.0146012 (300)\ttotal: 31.1s\tremaining: 1m 38s\n",
      "400:\tlearn: 0.0124212\ttest: 0.0127506\tbest: 0.0127499 (397)\ttotal: 41.8s\tremaining: 1m 28s\n",
      "500:\tlearn: 0.0116487\ttest: 0.0121946\tbest: 0.0121946 (500)\ttotal: 52.9s\tremaining: 1m 19s\n",
      "600:\tlearn: 0.0110805\ttest: 0.0118833\tbest: 0.0118816 (594)\ttotal: 1m 3s\tremaining: 1m 8s\n",
      "700:\tlearn: 0.0102975\ttest: 0.0112753\tbest: 0.0112753 (700)\ttotal: 1m 14s\tremaining: 58.7s\n",
      "800:\tlearn: 0.0098922\ttest: 0.0110416\tbest: 0.0110383 (770)\ttotal: 1m 25s\tremaining: 47.7s\n",
      "900:\tlearn: 0.0093256\ttest: 0.0107059\tbest: 0.0107059 (900)\ttotal: 1m 35s\tremaining: 37.1s\n",
      "1000:\tlearn: 0.0088839\ttest: 0.0104934\tbest: 0.0104888 (998)\ttotal: 1m 47s\tremaining: 26.6s\n",
      "1100:\tlearn: 0.0086644\ttest: 0.0104534\tbest: 0.0104534 (1099)\ttotal: 1m 57s\tremaining: 15.9s\n",
      "1200:\tlearn: 0.0084199\ttest: 0.0103746\tbest: 0.0103708 (1191)\ttotal: 2m 7s\tremaining: 5.22s\n",
      "1249:\tlearn: 0.0082383\ttest: 0.0103003\tbest: 0.0103003 (1249)\ttotal: 2m 13s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.01030025294\n",
      "bestIteration = 1249\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x16a62b890>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Split data into features and target\n",
    "X = train.drop(columns=['is_fraud'])\n",
    "y = train['is_fraud']\n",
    "X_test = test\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Train model now \n",
    "model = CatBoostClassifier(iterations=1250, depth=6, learning_rate=0.1, loss_function='Logloss', verbose=100)\n",
    "\n",
    "idxs = [X.columns.get_loc(col) for col in cat_col]\n",
    "\n",
    "model.fit(X_train, y_train, eval_set=(X_val, y_val), use_best_model=True, cat_features=idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score + Report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9854611807640238\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     65592\n",
      "           1       0.99      0.98      0.99      8549\n",
      "\n",
      "    accuracy                           1.00     74141\n",
      "   macro avg       0.99      0.99      0.99     74141\n",
      "weighted avg       1.00      1.00      1.00     74141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(X_val)\n",
    "\n",
    "f1 = f1_score(y_val, y_predict)\n",
    "print(f'F1 Score: {f1}')\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved as submission.csv\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': sample_submission['id'],\n",
    "    'is_fraud': y_test_pred\n",
    "})\n",
    "\n",
    "# Save the submission file\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file saved as submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
